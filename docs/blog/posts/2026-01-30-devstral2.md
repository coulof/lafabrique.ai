---
date:
  created: 2024-06-30
draft: true
---

Devstral 2 is one the hidden gem of the AI Agent ecosystem.

Devstral 2 is Mistral AI coding model. Released in december it comes with a bunch of useful features:
1. There are two size models (Devstral 2 with 123B parameters and Devstral Small 2 with 24B)
2. As usual with Mistral AI the models are under Open Source license
3. `vibe` [CLI coding agent](https://github.com/mistralai/mistral-vibe/) :material-github:
Checkout the [official blog post](https://mistral.ai/fr/news/devstral-2-vibe-cli) for more details
The version https://mistral.ai/fr/news/devstral-2-vibe-cli

I used the Build: Nightly on Platform: CUDA in version 12.9 with Package manager: `uv` and 

Other combos are easily selectable from : 
https://vllm.ai/#quick-start


Ubuntu 24.04 on WSL2
https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512#benchmark-results


https://developer.nvidia.com/cuda-12-9-1-download-archive



wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-13-1

nvcc --version


uv pip install -U vllm --pre --extra-index-url https://wheels.vllm.ai/nightly/cu129 --extra-index-url https://download.pytorch.org/whl/cu129 --index-strategy unsafe-best-match


vllm serve mistralai/Devstral-Small-2-24B-Instruct-2512     --max-model-len 262144 --tensor-parallel-size 1     --tool-call-parser mistral --enable-auto-tool-choice



Retester avec CUDA 13

uv pip install -U vllm --pre --extra-index-url https://wheels.vllm.ai/nightly/cu130 --extra-index-url https://download.pytorch.org/whl/cu130 --index-strategy unsafe-best-match


vllm serve mistralai/Devstral-Small-2-24B-Instruct-2512 \
    --max-model-len 8192 \
    --gpu-memory-utilization 0.95 \
    --tensor-parallel-size 1 \
    --tool-call-parser mistral \
    --enable-auto-tool-choice 2>&1 | tee vllm.log



---
Devstral 2 & `vibe` by Mistral AI :  the hidden gems of the AI Coding Agent.


Since about a year I'm working almost daily with different coding assistants depending on my mood or constraints.

I have been able to use and test, Windsurf & Tabnine at the job ; while I was a fervant user of Copilot then Claude code.

Recently I came across Devstral 2 & to me it replaced Claude Code in my workflow for the following reason:
1. It is beautiful ! Checkout the blog post announcement, the docs and the tool itself. There is a true value in working in a beautiful environment.
2. On the benchmark of me, myself & I, Devstral 2 performs as good as Claude Code. Not everything is perfect 
3. It is free (or at least way cheaper than Claude Code) & Open Source. You have 1 Million toekn for trial then ; $0.10/$0.30 for Devstral Small 2. In Claude code I'm blocked at least once a day, even after playing with `/compact`
4. It is slower than Claude Code but... You can run it entirely on your local machine.

The documentation to run it locally is rather loose and I had to fight a little bit to be able to run.

Check out this blog for the details on how to run Devstral 2 small + `vibe` on Ubuntu 24.04 on WSL2 with an NVIDIA GPU :
